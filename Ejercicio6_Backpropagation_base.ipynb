{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSCAlxho/UefM1+Wjuobpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarinaRmzG/Neuronal-Networks/blob/main/Ejercicio6_Backpropagation_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retropropagación a un paso\n",
        "\n",
        "La retropropagación nos brinda un mecanismo para entrenar redes de más de una capa. Su funcionamiento traslada el error en la predicción hacia atŕas usando la derivada parcial de dicho error con respecto de cada uno de los pesos. Es decir,\n",
        "\n",
        "$$\n",
        "\t\t\\frac{\\partial E}{\\partial w_{ho}} = \\frac{\\partial E}{\\partial h_o} \\frac{\\partial h_o}{\\partial w_{ho}}  =   \\frac{\\partial E}{\\partial h_o} y_h\n",
        "$$\n",
        "\n",
        "En este primer programa implementaremos el algoritmo de retropropagación para determinar los incrementos que debe tener cada capa de la red. En un siguiente ejercicio realizaremos todo el proceso de retropropagación."
      ],
      "metadata": {
        "id": "bd4ENIUIKIzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XNOQTKvVIsOh"
      },
      "outputs": [],
      "source": [
        "# Importamos paquetes\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones necesarias\n",
        "#Calcula la derivada de la función sigmoide en un punto 'x'.\n",
        "def sigmoid_prime(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "#Calcula la función sigmoide en un punto 'x'.\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "eHbB4D6qJbNl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de entrada\n",
        "# - 'x' es el vector de entrada que contiene los datos de entrada.\n",
        "x = np.array([0.5, 0.1, -0.2])\n",
        "# - 'target' es el vector de objetivo que contiene los valores a los que se desea llegar.\n",
        "target = 0.6\n",
        "# - 'learnrate' es la tasa de aprendizaje que se utiliza para ajustar los parámetros durante el proceso de optimización.\n",
        "learnrate = 0.5"
      ],
      "metadata": {
        "id": "e1M3cJQEJrSN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pesos de las conexiones entre capas\n",
        "weights_input_hidden = np.array([[0.5, -0.6],\n",
        "                                 [0.1, -0.2],\n",
        "                                 [0.1, 0.7]])\n",
        "print(weights_input_hidden)\n",
        "weights_hidden_output = np.array([0.1, -0.3])\n",
        "print(weights_hidden_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1150ucKJvm8",
        "outputId": "a0a721b9-da77-4b79-c947-9a1e8e0d3554"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.5 -0.6]\n",
            " [ 0.1 -0.2]\n",
            " [ 0.1  0.7]]\n",
            "[ 0.1 -0.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pase frontal\n",
        "\n",
        "Definimos el comportamiento de la red en el pase frontal.\n",
        "\n",
        "$$\n",
        "\\hat{y} = f(WX)\n",
        "$$"
      ],
      "metadata": {
        "id": "WwSBuLNbKP5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Paso hacia adelante (Forward pass)\n",
        "# Cálculo de la entrada a la capa oculta\n",
        "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
        "print(\"Entrada: \",hidden_layer_input)\n",
        "# Cálculo de la salida de la capa oculta utilizando la función sigmoide\n",
        "hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "print(\"Salida de la capa oculta: \",hidden_layer_output)\n",
        "# Cálculo de la entrada a la capa de salida\n",
        "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "print(\"Entrada 2: \",output_layer_in)\n",
        "# Cálculo de la salida de la red utilizando la función sigmoide\n",
        "output = sigmoid(output_layer_in)\n",
        "print(\"Salida de la red: \",output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQKmWIN7Jz1H",
        "outputId": "340caf3b-2bf0-4e01-ba69-d728f8f55ceb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada:  [ 0.24 -0.46]\n",
            "Salida de la capa oculta:  [0.55971365 0.38698582]\n",
            "Entrada 2:  -0.06012438223148006\n",
            "Salida de la red:  0.48497343084992534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pase hacia atrás\n",
        "\n",
        "Calcula el cambio que deben de tener los pesos de acuerdo al error. Recordemos que para la capa de salida el término de error que se aplica es:\n",
        "\n",
        "$$\n",
        "\\delta_o = (y-\\hat{y})f'(h)\n",
        "$$\n",
        "\n",
        "Y para la capa oculta:\n",
        "\n",
        "$$\n",
        "\\delta_h = \\delta_o w_{h,o} f'(h_h)\n",
        "$$\n",
        "\n",
        "este último término de error es diferente para cada neurona con índice $h$ de la capa oculta. Es decir tendremos tantas h como neuronas tenga la capa oculta. Nota que aunque el ejercicio se puede resolver usando vectores e índices, lo implementaremos usando notación matricial."
      ],
      "metadata": {
        "id": "_DMf5886KY2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Paso hacia atrás (Backwards pass)\n",
        "# Cálculo del error\n",
        "error = target - output\n",
        "print(\"Error:\",error)\n",
        "# Cálculo del gradiente de error para la capa de salida\n",
        "del_err_output = error * sigmoid_prime(output_layer_in)\n",
        "print(\"Gradiente de error capa de salida: \",del_err_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx8czX5nJ21W",
        "outputId": "0fcb18b8-1285-425d-e8bf-69659412a453"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 0.11502656915007464\n",
            "Gradiente de error capa de salida:  0.028730669543515015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo del gradiente de error para la capa oculta\n",
        "del_err_hidden = del_err_output * np.multiply(weights_hidden_output, sigmoid_prime(hidden_layer_input))\n",
        "print(\"Gradiente de error capa oculta: \",del_err_hidden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAB9_kYdCah_",
        "outputId": "80b78000-0648-495a-b08f-1ff39cb74b87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradiente de error capa oculta:  [ 0.00070802 -0.00204471]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya que sabemos los términos de error que aplican en cada capa, procedemos a determinar los incrementos en cada capa.\n",
        "\n",
        "$$\n",
        "\\Delta w_{h,o} = \\Delta w_{h,o} + \\delta_o \\hat{y}_h\n",
        "$$\n",
        "\n",
        "$$\\Delta w_{i,h} = \\Delta w_{i,h} + \\delta_h x_i$$"
      ],
      "metadata": {
        "id": "LxZ82mYGKmEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo del cambio en los pesos entre la capa oculta y la capa de salida\n",
        "delta_w_h_o = learnrate * del_err_output * hidden_layer_output\n",
        "\n",
        "# Cálculo del cambio en los pesos entre la capa de entrada y la capa oculta\n",
        "delta_w_i_h = learnrate * (del_err_hidden * x[:, None])"
      ],
      "metadata": {
        "id": "p6V67cCQKro3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impresión de los cambios en los pesos\n",
        "print('Incremento de los pesos oculta a salida:')\n",
        "print(delta_w_h_o)\n",
        "\n",
        "print('Incremento de los pesos de entrada a oculta:')\n",
        "print(delta_w_i_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkFmeKKnJ4_1",
        "outputId": "a3be451f-99f6-4f21-d4bc-7618f54012cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incremento de los pesos oculta a salida:\n",
            "[0.00804047 0.00555918]\n",
            "Incremento de los pesos de entrada a oculta:\n",
            "[[ 1.77005547e-04 -5.11178506e-04]\n",
            " [ 3.54011093e-05 -1.02235701e-04]\n",
            " [-7.08022187e-05  2.04471402e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusión\n",
        "Durante el proceso de retropropagación, se calculan los gradientes de error en cada capa, lo que permite ajustar los pesos de la red para minimizar el error y mejorar la capacidad de la red neuronal para realizar predicciones."
      ],
      "metadata": {
        "id": "PBKWyjE2XNG2"
      }
    }
  ]
}