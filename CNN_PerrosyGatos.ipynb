{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarinaRmzG/Neuronal-Networks/blob/main/CNN_PerrosyGatos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YFovej9rgbV3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data():\n",
        "    \"\"\"\n",
        "    Descarga y prepara los datos descargando un archivo ZIP y extrayendo su contenido.\n",
        "\n",
        "    Returns:\n",
        "        carpeta_zip (str): La ruta al archivo ZIP descargado y extraído.\n",
        "    \"\"\"\n",
        "    print(\"Descargando ZIP de datos\")\n",
        "\n",
        "    # Especifica la URL del archivo ZIP de datos.\n",
        "    url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "    # Utiliza la función get_file de TensorFlow para descargar el archivo ZIP y extraer su contenido.\n",
        "    carpeta_zip = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=url, extract=True)\n",
        "\n",
        "    return carpeta_zip"
      ],
      "metadata": {
        "id": "4HiFgdyGgg-W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def definir_rutas(carpeta_zip):\n",
        "    \"\"\"\n",
        "    Define las rutas a los directorios relevantes a partir de la ruta del archivo ZIP descargado.\n",
        "\n",
        "    Args:\n",
        "        carpeta_zip (str): La ruta al archivo ZIP descargado que contiene los datos.\n",
        "\n",
        "    Returns:\n",
        "        carpeta_entrenamiento (str): La ruta al directorio de entrenamiento.\n",
        "        carpeta_validacion (str): La ruta al directorio de validación.\n",
        "        carp_entren_gatos (str): La ruta al directorio de imágenes de entrenamiento de gatos.\n",
        "        carpeta_entren_perros (str): La ruta al directorio de imágenes de entrenamiento de perros.\n",
        "        carpeta_val_gatos (str): La ruta al directorio de imágenes de validación de gatos.\n",
        "        carpeta_val_perros (str): La ruta al directorio de imágenes de validación de perros.\n",
        "    \"\"\"\n",
        "    # Obtiene la carpeta base donde se extrajeron los datos del archivo ZIP.\n",
        "    carpeta_base = os.path.join(os.path.dirname(carpeta_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "    # Define las rutas a los directorios relevantes dentro de la estructura de carpetas.\n",
        "    carpeta_entrenamiento = os.path.join(carpeta_base, 'train')\n",
        "    carpeta_validacion = os.path.join(carpeta_base, 'validation')\n",
        "    carp_entren_gatos = os.path.join(carpeta_entrenamiento, 'cats')\n",
        "    carpeta_entren_perros = os.path.join(carpeta_entrenamiento, 'dogs')\n",
        "    carpeta_val_gatos = os.path.join(carpeta_validacion, 'cats')\n",
        "    carpeta_val_perros = os.path.join(carpeta_validacion, 'dogs')\n",
        "\n",
        "    return carpeta_entrenamiento, carpeta_validacion, carp_entren_gatos, carpeta_entren_perros,carpeta_val_gatos, carpeta_val_perros"
      ],
      "metadata": {
        "id": "jjKQtoiTi7LV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(carp_entren_gatos, carpeta_entren_perros, carpeta_val_gatos, carpeta_val_perros):\n",
        "    \"\"\"\n",
        "    Calcula y devuelve el número total de ejemplos en los conjuntos de datos de entrenamiento y validación.\n",
        "\n",
        "    Args:\n",
        "        carp_entren_gatos (str): La ruta al directorio que contiene imágenes de entrenamiento de gatos.\n",
        "        carpeta_entren_perros (str): La ruta al directorio que contiene imágenes de entrenamiento de perros.\n",
        "        carpeta_val_gatos (str): La ruta al directorio que contiene imágenes de validación de gatos.\n",
        "        carpeta_val_perros (str): La ruta al directorio que contiene imágenes de validación de perros.\n",
        "\n",
        "    Returns:\n",
        "        total_entrenamiento (int): El número total de ejemplos en el conjunto de datos de entrenamiento.\n",
        "        total_val (int): El número total de ejemplos en el conjunto de datos de validación.\n",
        "    \"\"\"\n",
        "    # Calcula el número de ejemplos en cada conjunto de datos.\n",
        "    num_gatos_entren = len(os.listdir(carp_entren_gatos))\n",
        "    num_perros_entren = len(os.listdir(carpeta_entren_perros))\n",
        "    num_gatos_val = len(os.listdir(carpeta_val_gatos))\n",
        "    num_perros_val = len(os.listdir(carpeta_val_perros))\n",
        "\n",
        "    # Calcula el número total de ejemplos en los conjuntos de datos de entrenamiento y validación.\n",
        "    total_entrenamiento = num_gatos_entren + num_perros_entren\n",
        "    total_val = num_gatos_val + num_perros_val\n",
        "\n",
        "    return total_entrenamiento, total_val"
      ],
      "metadata": {
        "id": "GmYeb7d1jMHU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation():\n",
        "    \"\"\"\n",
        "    Realiza aumento de datos mediante la configuración de un generador de datos de entrenamiento.\n",
        "\n",
        "    Returns:\n",
        "        image_gen_entrenamiento: Un generador de datos de entrenamiento configurado con técnicas de aumento de datos.\n",
        "    \"\"\"\n",
        "    print(\"Realizando aumento de datos\")\n",
        "\n",
        "    # Crea un objeto ImageDataGenerator para aplicar técnicas de aumento de datos.\n",
        "    image_gen_entrenamiento = ImageDataGenerator(\n",
        "        rescale=1./255,  # Normaliza los valores de píxeles en el rango [0, 1]\n",
        "        rotation_range=40,  # Rango de rotación en grados\n",
        "        width_shift_range=0.2,  # Rango de cambio de ancho\n",
        "        height_shift_range=0.2,  # Rango de cambio de altura\n",
        "        shear_range=0.2,  # Rango de deformación (cizalla)\n",
        "        zoom_range=0.2,  # Rango de aumento (zoom)\n",
        "        horizontal_flip=True,  # Volteo horizontal aleatorio\n",
        "        fill_mode='nearest'  # Modo de llenado para áreas recién creadas\n",
        "    )\n",
        "\n",
        "    return image_gen_entrenamiento"
      ],
      "metadata": {
        "id": "m8Txr_1MjlhN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(image_gen_entrenamiento, carpeta_entrenamiento, TAMANO_LOTE, TAMANO_IMG):\n",
        "    \"\"\"\n",
        "    Genera un generador de datos de entrenamiento a partir de un directorio de imágenes de entrenamiento.\n",
        "\n",
        "    Args:\n",
        "        image_gen_entrenamiento (tf.keras.preprocessing.image.ImageDataGenerator): El generador de datos de entrenamiento.\n",
        "        carpeta_entrenamiento (str): La ruta al directorio que contiene las imágenes de entrenamiento.\n",
        "        TAMANO_LOTE (int): El tamaño del lote utilizado para cargar imágenes durante el entrenamiento.\n",
        "        TAMANO_IMG (int): El tamaño al que se redimensionan las imágenes de entrenamiento.\n",
        "\n",
        "    Returns:\n",
        "        data_gen_entrenamiento: Un generador de datos de entrenamiento.\n",
        "    \"\"\"\n",
        "    # Utiliza el generador de datos de entrenamiento para cargar y preprocesar las imágenes de entrenamiento.\n",
        "    data_gen_entrenamiento = image_gen_entrenamiento.flow_from_directory(\n",
        "        batch_size=TAMANO_LOTE,  # Tamaño del lote de imágenes\n",
        "        directory=carpeta_entrenamiento,  # Directorio que contiene las imágenes de entrenamiento\n",
        "        shuffle=True,  # Baraja el orden de las imágenes de entrenamiento\n",
        "        target_size=(TAMANO_IMG, TAMANO_IMG),  # Tamaño al que se redimensionan las imágenes\n",
        "        class_mode='binary'  # Modo de clasificación, en este caso, clasificación binaria\n",
        "    )\n",
        "\n",
        "    return data_gen_entrenamiento"
      ],
      "metadata": {
        "id": "bOvNsYAnjv57"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_validation_data(carpeta_validacion, TAMANO_LOTE, TAMANO_IMG):\n",
        "    \"\"\"\n",
        "    Genera un generador de datos de validación a partir de un directorio de imágenes de validación.\n",
        "\n",
        "    Args:\n",
        "        carpeta_validacion (str): La ruta al directorio que contiene las imágenes de validación.\n",
        "        TAMANO_LOTE (int): El tamaño del lote utilizado para cargar imágenes durante la validación.\n",
        "        TAMANO_IMG (int): El tamaño al que se redimensionan las imágenes de validación.\n",
        "\n",
        "    Returns:\n",
        "        data_gen_validacion: Un generador de datos de validación.\n",
        "    \"\"\"\n",
        "    # Crea un objeto ImageDataGenerator para el preprocesamiento de las imágenes de validación.\n",
        "    image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Utiliza el generador de datos de imágenes para cargar y preprocesar las imágenes de validación.\n",
        "    data_gen_validacion = image_gen_val.flow_from_directory(\n",
        "        batch_size=TAMANO_LOTE,  # Tamaño del lote de imágenes\n",
        "        directory=carpeta_validacion,  # Directorio que contiene las imágenes de validación\n",
        "        target_size=(TAMANO_IMG, TAMANO_IMG),  # Tamaño al que se redimensionan las imágenes\n",
        "        class_mode='binary'  # Modo de clasificación, en este caso, clasificación binaria\n",
        "    )\n",
        "\n",
        "    return data_gen_validacion"
      ],
      "metadata": {
        "id": "n8pkrCbaj7SE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Crear un modelo secuencial\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Agregar una capa de convolución 2D con 32 filtros, un tamaño de kernel de (3,3) y función de activación ReLU.\n",
        "    # La capa de entrada espera imágenes de 150x150 píxeles con 3 canales de color (RGB).\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "\n",
        "    # Agregar una capa de MaxPooling 2D para reducir el tamaño de la representación.\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    # Agregar otra capa de convolución 2D con 64 filtros y ReLU.\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "    # Otra capa de MaxPooling 2D.\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    # Agregar una capa de convolución 2D con 128 filtros y ReLU.\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "    # Otra capa de MaxPooling 2D.\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    # Agregar otra capa de convolución 2D con 128 filtros y ReLU.\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "    # Otra capa de MaxPooling 2D.\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    # Agregar una capa de Dropout para la regularización, evitando el sobreajuste.\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    # Aplanar la salida de las capas anteriores para conectarla a capas densas (fully connected).\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # Agregar una capa densa con 512 neuronas y función de activación ReLU.\n",
        "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "\n",
        "    # Agregar la capa de salida con 2 neuronas para la clasificación binaria (perro o gato).\n",
        "    # No se aplica una función de activación aquí, ya que se utilizará la función de activación softmax\n",
        "    # en la función de pérdida durante el entrenamiento.\n",
        "    model.add(tf.keras.layers.Dense(2))\n",
        "\n",
        "    return model  # Devolver el modelo construido"
      ],
      "metadata": {
        "id": "p5HRxSpihlGV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilar modelos. Usar crossentropy binario ya que tenemos solo 2 opciones (perro o gato)\n",
        "def compile_model(model):\n",
        "    # Compilar el modelo con el optimizador 'adam', una función de pérdida de entropía cruzada categórica dispersa\n",
        "    # (utilizada para clasificación con etiquetas enteras) y la métrica de 'accuracy' para evaluar el rendimiento.\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )"
      ],
      "metadata": {
        "id": "aMEWiI86iKyu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data_gen_entrenamiento, data_gen_validacion, epocas, total_entrenamiento, TAMANO_LOTE, total_val):\n",
        "    \"\"\"\n",
        "    Entrena un modelo de red neuronal utilizando conjuntos de datos de entrenamiento y validación.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): El modelo de red neuronal que se va a entrenar.\n",
        "        data_gen_entrenamiento (tf.keras.preprocessing.image.ImageDataGenerator): Generador de datos de entrenamiento.\n",
        "        data_gen_validacion (tf.keras.preprocessing.image.ImageDataGenerator): Generador de datos de validación.\n",
        "        epocas (int): El número de épocas de entrenamiento.\n",
        "        total_entrenamiento (int): El número total de ejemplos de entrenamiento.\n",
        "        TAMANO_LOTE (int): El tamaño del lote utilizado durante el entrenamiento.\n",
        "        total_val (int): El número total de ejemplos de validación.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(\"Entrenando modelo...\")\n",
        "\n",
        "    # El método fit_generator se utiliza para entrenar el modelo con generadores de datos.\n",
        "    history = model.fit_generator(\n",
        "        data_gen_entrenamiento,  # Generador de datos de entrenamiento\n",
        "        steps_per_epoch=int(np.ceil(total_entrenamiento / float(TAMANO_LOTE))),  # Pasos por época\n",
        "        epochs=epocas,  # Número de épocas de entrenamiento\n",
        "        validation_data=data_gen_validacion,  # Datos de validación\n",
        "        validation_steps=int(np.ceil(total_val / float(TAMANO_LOTE)))  # Pasos de validación\n",
        "    )\n",
        "\n",
        "    print(\"Modelo entrenado!\")"
      ],
      "metadata": {
        "id": "hIUi8mapkQ-a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    TAMANO_LOTE = 100\n",
        "    TAMANO_IMG = 150\n",
        "    epocas = 60\n",
        "    carpeta_zip = prepare_data()\n",
        "    carpeta_entrenamiento, carpeta_validacion, carp_entren_gatos, carpeta_entren_perros, carpeta_val_gatos, carpeta_val_perros = definir_rutas(carpeta_zip)\n",
        "    total_entrenamiento, total_val = get_data(carp_entren_gatos, carpeta_entren_perros, carpeta_val_gatos, carpeta_val_perros)\n",
        "    image_gen_entrenamiento = data_augmentation()\n",
        "    data_gen_entrenamiento = generate_training_data(image_gen_entrenamiento, carpeta_entrenamiento, TAMANO_LOTE, TAMANO_IMG)\n",
        "    data_gen_validacion = generate_validation_data(carpeta_validacion, TAMANO_LOTE, TAMANO_IMG)\n",
        "    model = create_model()\n",
        "    compile_model(model)\n",
        "    train_model(model, data_gen_entrenamiento, data_gen_validacion, epocas, total_entrenamiento, TAMANO_LOTE, total_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEnh6fzRlAnq",
        "outputId": "e220bec1-d3e6-4572-9a5c-84800f54dec1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando ZIP de datos\n",
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68606236/68606236 [==============================] - 0s 0us/step\n",
            "Realizando aumento de datos\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Entrenando modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-65b753f5ec13>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "20/20 [==============================] - 19s 824ms/step - loss: 0.7103 - accuracy: 0.5040 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
            "Epoch 2/60\n",
            "20/20 [==============================] - 18s 931ms/step - loss: 0.6920 - accuracy: 0.5115 - val_loss: 0.6890 - val_accuracy: 0.6090\n",
            "Epoch 3/60\n",
            "20/20 [==============================] - 17s 836ms/step - loss: 0.6831 - accuracy: 0.5615 - val_loss: 0.6468 - val_accuracy: 0.6290\n",
            "Epoch 4/60\n",
            "20/20 [==============================] - 18s 874ms/step - loss: 0.6926 - accuracy: 0.5340 - val_loss: 0.6915 - val_accuracy: 0.5230\n",
            "Epoch 5/60\n",
            "20/20 [==============================] - 17s 835ms/step - loss: 0.6901 - accuracy: 0.5285 - val_loss: 0.6835 - val_accuracy: 0.5830\n",
            "Epoch 6/60\n",
            "20/20 [==============================] - 18s 880ms/step - loss: 0.6830 - accuracy: 0.5670 - val_loss: 0.6581 - val_accuracy: 0.6300\n",
            "Epoch 7/60\n",
            "20/20 [==============================] - 17s 838ms/step - loss: 0.6652 - accuracy: 0.5950 - val_loss: 0.6776 - val_accuracy: 0.5480\n",
            "Epoch 8/60\n",
            "20/20 [==============================] - 17s 869ms/step - loss: 0.6652 - accuracy: 0.5930 - val_loss: 0.6334 - val_accuracy: 0.6550\n",
            "Epoch 9/60\n",
            "20/20 [==============================] - 19s 910ms/step - loss: 0.6622 - accuracy: 0.5900 - val_loss: 0.6636 - val_accuracy: 0.5740\n",
            "Epoch 10/60\n",
            "20/20 [==============================] - 17s 843ms/step - loss: 0.6516 - accuracy: 0.6145 - val_loss: 0.6255 - val_accuracy: 0.6360\n",
            "Epoch 11/60\n",
            "20/20 [==============================] - 17s 857ms/step - loss: 0.6293 - accuracy: 0.6395 - val_loss: 0.5986 - val_accuracy: 0.6810\n",
            "Epoch 12/60\n",
            "20/20 [==============================] - 18s 893ms/step - loss: 0.6258 - accuracy: 0.6445 - val_loss: 0.6236 - val_accuracy: 0.6300\n",
            "Epoch 13/60\n",
            "20/20 [==============================] - 17s 852ms/step - loss: 0.6102 - accuracy: 0.6645 - val_loss: 0.5921 - val_accuracy: 0.6950\n",
            "Epoch 14/60\n",
            "20/20 [==============================] - 17s 842ms/step - loss: 0.6088 - accuracy: 0.6765 - val_loss: 0.5953 - val_accuracy: 0.6620\n",
            "Epoch 15/60\n",
            "20/20 [==============================] - 18s 902ms/step - loss: 0.6071 - accuracy: 0.6680 - val_loss: 0.5875 - val_accuracy: 0.6830\n",
            "Epoch 16/60\n",
            "20/20 [==============================] - 17s 853ms/step - loss: 0.6019 - accuracy: 0.6730 - val_loss: 0.5817 - val_accuracy: 0.6820\n",
            "Epoch 17/60\n",
            "20/20 [==============================] - 18s 894ms/step - loss: 0.5867 - accuracy: 0.6815 - val_loss: 0.5742 - val_accuracy: 0.6840\n",
            "Epoch 18/60\n",
            "20/20 [==============================] - 17s 848ms/step - loss: 0.5935 - accuracy: 0.6715 - val_loss: 0.5670 - val_accuracy: 0.6960\n",
            "Epoch 19/60\n",
            "20/20 [==============================] - 17s 847ms/step - loss: 0.5718 - accuracy: 0.7065 - val_loss: 0.5448 - val_accuracy: 0.7210\n",
            "Epoch 20/60\n",
            "20/20 [==============================] - 17s 854ms/step - loss: 0.5802 - accuracy: 0.6870 - val_loss: 0.5491 - val_accuracy: 0.7130\n",
            "Epoch 21/60\n",
            "20/20 [==============================] - 18s 889ms/step - loss: 0.5823 - accuracy: 0.6955 - val_loss: 0.5509 - val_accuracy: 0.7180\n",
            "Epoch 22/60\n",
            "20/20 [==============================] - 17s 855ms/step - loss: 0.5739 - accuracy: 0.6910 - val_loss: 0.5607 - val_accuracy: 0.6940\n",
            "Epoch 23/60\n",
            "20/20 [==============================] - 18s 889ms/step - loss: 0.5618 - accuracy: 0.7210 - val_loss: 0.5735 - val_accuracy: 0.6920\n",
            "Epoch 24/60\n",
            "20/20 [==============================] - 17s 862ms/step - loss: 0.5549 - accuracy: 0.7190 - val_loss: 0.5217 - val_accuracy: 0.7400\n",
            "Epoch 25/60\n",
            "20/20 [==============================] - 18s 889ms/step - loss: 0.5532 - accuracy: 0.7190 - val_loss: 0.5735 - val_accuracy: 0.6830\n",
            "Epoch 26/60\n",
            "20/20 [==============================] - 17s 859ms/step - loss: 0.5471 - accuracy: 0.7105 - val_loss: 0.5077 - val_accuracy: 0.7520\n",
            "Epoch 27/60\n",
            "20/20 [==============================] - 17s 859ms/step - loss: 0.5299 - accuracy: 0.7300 - val_loss: 0.5395 - val_accuracy: 0.7250\n",
            "Epoch 28/60\n",
            "20/20 [==============================] - 17s 850ms/step - loss: 0.5258 - accuracy: 0.7410 - val_loss: 0.5308 - val_accuracy: 0.7360\n",
            "Epoch 29/60\n",
            "20/20 [==============================] - 17s 870ms/step - loss: 0.5638 - accuracy: 0.7045 - val_loss: 0.5089 - val_accuracy: 0.7490\n",
            "Epoch 30/60\n",
            "20/20 [==============================] - 17s 856ms/step - loss: 0.5146 - accuracy: 0.7385 - val_loss: 0.5529 - val_accuracy: 0.7060\n",
            "Epoch 31/60\n",
            "20/20 [==============================] - 18s 899ms/step - loss: 0.5185 - accuracy: 0.7505 - val_loss: 0.5069 - val_accuracy: 0.7510\n",
            "Epoch 32/60\n",
            "20/20 [==============================] - 16s 815ms/step - loss: 0.5099 - accuracy: 0.7500 - val_loss: 0.4977 - val_accuracy: 0.7660\n",
            "Epoch 33/60\n",
            "20/20 [==============================] - 16s 819ms/step - loss: 0.4980 - accuracy: 0.7525 - val_loss: 0.4961 - val_accuracy: 0.7550\n",
            "Epoch 34/60\n",
            "20/20 [==============================] - 18s 907ms/step - loss: 0.4850 - accuracy: 0.7610 - val_loss: 0.4711 - val_accuracy: 0.7780\n",
            "Epoch 35/60\n",
            "20/20 [==============================] - 16s 819ms/step - loss: 0.4901 - accuracy: 0.7530 - val_loss: 0.5159 - val_accuracy: 0.7520\n",
            "Epoch 36/60\n",
            "20/20 [==============================] - 16s 823ms/step - loss: 0.5191 - accuracy: 0.7400 - val_loss: 0.5168 - val_accuracy: 0.7610\n",
            "Epoch 37/60\n",
            "20/20 [==============================] - 17s 867ms/step - loss: 0.5108 - accuracy: 0.7610 - val_loss: 0.4881 - val_accuracy: 0.7830\n",
            "Epoch 38/60\n",
            "20/20 [==============================] - 17s 869ms/step - loss: 0.5240 - accuracy: 0.7400 - val_loss: 0.4769 - val_accuracy: 0.7810\n",
            "Epoch 39/60\n",
            "20/20 [==============================] - 16s 826ms/step - loss: 0.4882 - accuracy: 0.7690 - val_loss: 0.4805 - val_accuracy: 0.7770\n",
            "Epoch 40/60\n",
            "20/20 [==============================] - 17s 826ms/step - loss: 0.4698 - accuracy: 0.7745 - val_loss: 0.4561 - val_accuracy: 0.7920\n",
            "Epoch 41/60\n",
            "20/20 [==============================] - 17s 830ms/step - loss: 0.4563 - accuracy: 0.7900 - val_loss: 0.4611 - val_accuracy: 0.7840\n",
            "Epoch 42/60\n",
            "20/20 [==============================] - 17s 870ms/step - loss: 0.4628 - accuracy: 0.7780 - val_loss: 0.4611 - val_accuracy: 0.7840\n",
            "Epoch 43/60\n",
            "20/20 [==============================] - 17s 832ms/step - loss: 0.4687 - accuracy: 0.7800 - val_loss: 0.4764 - val_accuracy: 0.7730\n",
            "Epoch 44/60\n",
            "20/20 [==============================] - 17s 838ms/step - loss: 0.4573 - accuracy: 0.7955 - val_loss: 0.4353 - val_accuracy: 0.7900\n",
            "Epoch 45/60\n",
            "20/20 [==============================] - 17s 864ms/step - loss: 0.4492 - accuracy: 0.7980 - val_loss: 0.4389 - val_accuracy: 0.7920\n",
            "Epoch 46/60\n",
            "20/20 [==============================] - 17s 833ms/step - loss: 0.4486 - accuracy: 0.7970 - val_loss: 0.4417 - val_accuracy: 0.7830\n",
            "Epoch 47/60\n",
            "20/20 [==============================] - 17s 861ms/step - loss: 0.4251 - accuracy: 0.7950 - val_loss: 0.4264 - val_accuracy: 0.8080\n",
            "Epoch 48/60\n",
            "20/20 [==============================] - 17s 833ms/step - loss: 0.4182 - accuracy: 0.8240 - val_loss: 0.4149 - val_accuracy: 0.8100\n",
            "Epoch 49/60\n",
            "20/20 [==============================] - 17s 871ms/step - loss: 0.4412 - accuracy: 0.7945 - val_loss: 0.4442 - val_accuracy: 0.7830\n",
            "Epoch 50/60\n",
            "20/20 [==============================] - 17s 830ms/step - loss: 0.4142 - accuracy: 0.8125 - val_loss: 0.4223 - val_accuracy: 0.8190\n",
            "Epoch 51/60\n",
            "20/20 [==============================] - 17s 836ms/step - loss: 0.4010 - accuracy: 0.8140 - val_loss: 0.4234 - val_accuracy: 0.7960\n",
            "Epoch 52/60\n",
            "20/20 [==============================] - 18s 851ms/step - loss: 0.4185 - accuracy: 0.8065 - val_loss: 0.4613 - val_accuracy: 0.7790\n",
            "Epoch 53/60\n",
            "20/20 [==============================] - 17s 854ms/step - loss: 0.4201 - accuracy: 0.8035 - val_loss: 0.4237 - val_accuracy: 0.7990\n",
            "Epoch 54/60\n",
            "20/20 [==============================] - 17s 877ms/step - loss: 0.3997 - accuracy: 0.8220 - val_loss: 0.4118 - val_accuracy: 0.8080\n",
            "Epoch 55/60\n",
            "20/20 [==============================] - 17s 849ms/step - loss: 0.4129 - accuracy: 0.8120 - val_loss: 0.4124 - val_accuracy: 0.8090\n",
            "Epoch 56/60\n",
            "20/20 [==============================] - 17s 826ms/step - loss: 0.4094 - accuracy: 0.8050 - val_loss: 0.4346 - val_accuracy: 0.7980\n",
            "Epoch 57/60\n",
            "20/20 [==============================] - 17s 866ms/step - loss: 0.4084 - accuracy: 0.8075 - val_loss: 0.3943 - val_accuracy: 0.8310\n",
            "Epoch 58/60\n",
            "20/20 [==============================] - 17s 836ms/step - loss: 0.3844 - accuracy: 0.8280 - val_loss: 0.3968 - val_accuracy: 0.8180\n",
            "Epoch 59/60\n",
            "20/20 [==============================] - 16s 823ms/step - loss: 0.3737 - accuracy: 0.8270 - val_loss: 0.4069 - val_accuracy: 0.8120\n",
            "Epoch 60/60\n",
            "20/20 [==============================] - 17s 870ms/step - loss: 0.4130 - accuracy: 0.8210 - val_loss: 0.4065 - val_accuracy: 0.8260\n",
            "Modelo entrenado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6aK5pBaeNBd"
      },
      "source": [
        "#Exportar el modelo en formato h5\n",
        "model.save('perros-gatos.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAHnDcF9WuQP"
      },
      "source": [
        "#El equipo es Linux. Listemos el contenido de la carpeta actual para ver que se exporto el modelo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzpZjGgUWuN7"
      },
      "source": [
        "#Para convertirlo a tensorflow.js, primero debemos instalar la libreria\n",
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5uaQ_BWuLL"
      },
      "source": [
        "#Crear carpeta donde se colocaran los archivos resultantes\n",
        "!mkdir carpeta_salida"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_rtgd1_WuGk"
      },
      "source": [
        "#Realizar la exportacion a la carpeta de salida\n",
        "!tensorflowjs_converter --input_format keras perros-gatos.h5 carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd99qwADW4qt"
      },
      "source": [
        "#Confirmar que en la carpeta de salida se hayan generado los archivos. Deben aparecer archivos \"bin\" y \"json\"\n",
        "!ls carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeDA6P0CW4oa"
      },
      "source": [
        "#Para descargarlos, da clic del lado izquierdo en el icono de la carpeta\n",
        "#y expande carpeta_salida. En los archivos utiliza los 3 puntos para descargarlos"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}